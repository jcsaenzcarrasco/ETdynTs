\section{Discussion and Future Work} 
\label{sec:Concl} 
\label{sec:discussion}

\subsection{Final remarks}

We limit our discussion to dynamic trees. In particular, all data structures we discuss above can solve the dynamic connectivity problem for trees maintaining a forest under a finite sequence of edge insertions and deletions and supporting queries asking whether two vertices belong to the same tree or not.

The experiments we carried out provide a general overview of the strengths and weaknesses of the data structures presented in Sections \ref{sec:TechDes} and \ref{sec:Eval}. Although the results might change slightly if different implementations are tested or if a different architecture is used, some general observations can be made.

Firstly, we have presented \dyntset, a new approach to two existent functional data structures (i.e. finger trees and sets) for maintaining dynamic trees. This structure can manage $k$-degree trees, rooted or unrooted persistently whilst solving the dynamic trees problem. 

Although the updates are conceptually very simple, namely \link and \cut, the proof that both indeed take $O(\log n)$ time is rather inherited from the core structures. Such definitions are acyclic and involve $O(1)$ number of steps to perform each. 

Our experimental analysis has shown that the three operations we have implemented exceed the theoretical bounds by a $O(\log n)$ factor. Also, a native mechanism in the Haskell programming language, the lazy evaluation, is a crucial factor to achieve such performance. Nevertheless, the \link operation is slower that its imperative counterpart, by a factor of $O(\log n)$, is overcome in practice.

\subsection{Further work}

\tcr{Sets in Haskell are trees themselves, and it is odd to store a tree in every node of a tree. Can you take the finger tree, specialized to this particular monoidal annotation, and optimize it further more?}

Unfortunately, much of the simplicity of \dyntset data structure results from its use of sets as monoidal annotations, which allocate a $O(\log m)$ space per set within the host structure, i.e. finger tree, where $m \leq n$. Potential improvement suggests that benefits may accrue if we were to use higher order programming with effects, such as stateful computation or database-related structures rather than sets.

Uniqueness on edges allow to carry labels, therefore \dyntset could solve the dynamic trees problem from other approaches such as path-decomposition (i.e. link-cut trees) and tree-contraction. 

Parallelism can play an important speed up when calling functions such \conn. Recalling the its first lines, we have
\begin{lstlisting} [mathescape]
conn x y forest = case (nodeIn x forest, nodeIn y forest) of 
$\ldots$
\end{lstlisting}
Since the result of the leftist \code{nodeIn} is independent from the right one, both are suitable candidates to be evaluated in parallel. The pending research here is the time and space analysis between the sequential (both strict and lazy) against the parallel cases.

Finally, there is an evident need for a library of well-crafted test cases against which implementations of dynamic trees, graphs and applications can be tested. At present, for example, there is little to guide us when generating the update-sequences against which our structures are validated, and this raises a number of obvious issues. For example,

\begin{itemize}
\item Can we find test sets which guarantee coverage of key properties?
\item Which properties are we interested in?
\item If we know the general ratio of updates to queries (say), can we identify a more specific data structure to enhance efficiency still further?
\end{itemize}

These and other questions remain to be addressed, but we believe the quest for efficient dynamic data structures will become ever more important as seek to model, simplify and reason about the increasingly dynamic algorithmic structures in which modern culture is immersed and on which it depends.
